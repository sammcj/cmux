#!/usr/bin/env python3
"""
Provision Morph instances from an existing base snapshot, perform parallelized
environment setup that mirrors the Dockerfile, validate critical tooling, and
snapshot the configured system for multiple presets (standard + boosted by default).

The flow:
1. Boot an instance per preset from the provided base snapshot (default snapshot_i7l4i12s)
2. Expose the standard cmux HTTP services
3. Execute dependency graph tasks concurrently using Morph's async APIs
4. Run in-instance sanity checks (cargo/node/bun/uv/envd/envctl + service curls)
5. Snapshot the configured instance, optionally prompt for manual verification, and
   record the snapshot in packages/shared/src/morph-snapshots.json

Examples:
uv run --env-file .env ./scripts/snapshot.py
uv run --env-file .env ./scripts/snapshot.py --require-verify # do not use this flag unless explicitly asked
"""

from __future__ import annotations

import argparse
import asyncio
import atexit
import json
import os
import shutil
import shlex
import ssl
import subprocess
import sys
import tarfile
import tempfile
import textwrap
import traceback
import typing as t
import urllib.parse

from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path

import dotenv
import httpx
import paramiko
from morphcloud.api import ApiError, Instance, MorphCloudClient, Snapshot

from snapshot import (
    TaskRegistry,
    TaskContext,
    Console,
    ResourceProfile,
    TimingsCollector,
    HttpExecClient,
    run_task_graph,
    format_dependency_graph,
)

# ---------------------------------------------------------------------------
# Constants
# ---------------------------------------------------------------------------

EXEC_HTTP_PORT = 39375
EXEC_BINARY_NAME = "cmux-execd"
EXEC_REMOTE_PATH = "/usr/local/bin/cmux-execd"
EXEC_TEMP_PATH = "/tmp/cmux-execd"
EXEC_BUILD_TARGET_ENV = "CMUX_EXEC_TARGET"
DEFAULT_EXEC_BUILD_TARGET = "linux/amd64"
EXEC_SOURCE_PATH = Path("scripts/execd/main.go")
EXEC_BUILD_OUTPUT_DIR = Path("scripts/execd/dist")
VSCODE_HTTP_PORT = 39378
VNC_HTTP_PORT = 39380
CDP_HTTP_PORT = 39381
XTERM_HTTP_PORT = 39383
CDP_PROXY_BINARY_NAME = "cmux-cdp-proxy"
VNC_PROXY_BINARY_NAME = "cmux-vnc-proxy"
MORPH_SNAPSHOT_MANIFEST_PATH = (
    Path(__file__).resolve().parent.parent / "packages/shared/src/morph-snapshots.json"
)
CURRENT_MANIFEST_SCHEMA_VERSION = 1

# ---------------------------------------------------------------------------
# IDE Provider Configuration
# ---------------------------------------------------------------------------

IDE_PROVIDER_CODER = "coder"
IDE_PROVIDER_OPENVSCODE = "openvscode"
IDE_PROVIDER_CMUX_CODE = "cmux-code"
DEFAULT_IDE_PROVIDER = IDE_PROVIDER_CMUX_CODE

# Module-level IDE provider setting (set from args before task graph runs)
_ide_provider: str = DEFAULT_IDE_PROVIDER


def set_ide_provider(provider: str) -> None:
    global _ide_provider
    _ide_provider = provider


def get_ide_provider() -> str:
    return _ide_provider

# ---------------------------------------------------------------------------
# Manifest types and helpers
# ---------------------------------------------------------------------------


class MorphSnapshotVersionEntry(t.TypedDict):
    version: int
    snapshotId: str
    capturedAt: str


class MorphSnapshotPresetEntry(t.TypedDict):
    presetId: str
    label: str
    cpu: str
    memory: str
    disk: str
    versions: list[MorphSnapshotVersionEntry]
    description: t.NotRequired[str]


class MorphSnapshotManifestEntry(t.TypedDict):
    schemaVersion: int
    updatedAt: str
    presets: list[MorphSnapshotPresetEntry]


@dataclass(slots=True, frozen=True)
class SnapshotPresetPlan:
    preset_id: str
    label: str
    cpu_display: str
    memory_display: str
    disk_display: str
    vcpus: int
    memory_mib: int
    disk_size_mib: int


@dataclass(slots=True)
class SnapshotRunResult:
    preset: SnapshotPresetPlan
    snapshot: Snapshot
    captured_at: str
    vscode_url: str
    vnc_url: str
    instance_id: str

    def __init__(
        self,
        *,
        preset: SnapshotPresetPlan,
        snapshot: Snapshot,
        captured_at: str,
        vscode_url: str,
        vnc_url: str,
        instance_id: str,
    ) -> None:
        self.preset = preset
        self.snapshot = snapshot
        self.captured_at = captured_at
        self.vscode_url = vscode_url
        self.vnc_url = vnc_url
        self.instance_id = instance_id


def _iso_timestamp() -> str:
    return (
        datetime.now(tz=timezone.utc)
        .replace(microsecond=0)
        .isoformat()
        .replace("+00:00", "Z")
    )


def _coalesce_str(value: t.Any, default: str) -> str:
    if isinstance(value, str) and value:
        return value
    return default


def _coalesce_int(value: t.Any, default: int) -> int:
    try:
        parsed = int(value)
    except Exception:
        return default
    return parsed


def _normalize_manifest(manifest: MorphSnapshotManifestEntry) -> MorphSnapshotManifestEntry:
    presets: list[MorphSnapshotPresetEntry] = []
    for preset in manifest.get("presets", []):
        if not isinstance(preset, dict):
            continue
        versions: list[MorphSnapshotVersionEntry] = []
        for version in preset.get("versions", []):
            if not isinstance(version, dict):
                continue
            version_entry: MorphSnapshotVersionEntry = {
                "version": _coalesce_int(version.get("version"), 0),
                "snapshotId": _coalesce_str(version.get("snapshotId"), ""),
                "capturedAt": _coalesce_str(version.get("capturedAt"), _iso_timestamp()),
            }
            versions.append(version_entry)
        versions.sort(key=lambda entry: entry["version"])
        preset_entry: MorphSnapshotPresetEntry = {
            "presetId": _coalesce_str(preset.get("presetId"), ""),
            "label": _coalesce_str(preset.get("label"), ""),
            "cpu": _coalesce_str(preset.get("cpu"), ""),
            "memory": _coalesce_str(preset.get("memory"), ""),
            "disk": _coalesce_str(preset.get("disk"), ""),
            "versions": versions,
        }
        description = preset.get("description")
        if isinstance(description, str) and description:
            preset_entry["description"] = description
        presets.append(preset_entry)

    return {
        "schemaVersion": _coalesce_int(
            manifest.get("schemaVersion"), CURRENT_MANIFEST_SCHEMA_VERSION
        ),
        "updatedAt": _coalesce_str(manifest.get("updatedAt"), _iso_timestamp()),
        "presets": presets,
    }


def _load_manifest(console: Console) -> MorphSnapshotManifestEntry:
    if not MORPH_SNAPSHOT_MANIFEST_PATH.exists():
        return {
            "schemaVersion": CURRENT_MANIFEST_SCHEMA_VERSION,
            "updatedAt": _iso_timestamp(),
            "presets": [],
        }
    try:
        raw_manifest = json.loads(MORPH_SNAPSHOT_MANIFEST_PATH.read_text())
    except Exception as exc:
        raise RuntimeError(
            f"Failed to read morph snapshot manifest at {MORPH_SNAPSHOT_MANIFEST_PATH}: {exc}"
        ) from exc
    manifest = _normalize_manifest(raw_manifest)
    if manifest["schemaVersion"] != CURRENT_MANIFEST_SCHEMA_VERSION:
        console.always(
            f"Warning: manifest schema version {manifest['schemaVersion']} "
            f"differs from expected {CURRENT_MANIFEST_SCHEMA_VERSION}"
        )
    return manifest


def _write_manifest(manifest: MorphSnapshotManifestEntry) -> None:
    manifest_to_write = _normalize_manifest(manifest)
    MORPH_SNAPSHOT_MANIFEST_PATH.write_text(
        json.dumps(manifest_to_write, indent=2, sort_keys=False)
    )


def _update_manifest_with_snapshot(
    manifest: MorphSnapshotManifestEntry,
    preset: SnapshotPresetPlan,
    snapshot_id: str,
    captured_at: str,
) -> MorphSnapshotManifestEntry:
    updated_manifest = _normalize_manifest(manifest)
    preset_entry: MorphSnapshotPresetEntry | None = None
    for candidate in updated_manifest["presets"]:
        if candidate.get("presetId") == preset.preset_id:
            preset_entry = candidate
            break

    if preset_entry is None:
        preset_entry = {
            "presetId": preset.preset_id,
            "label": preset.label,
            "cpu": preset.cpu_display,
            "memory": preset.memory_display,
            "disk": preset.disk_display,
            "versions": [],
        }
        updated_manifest["presets"].append(preset_entry)
    else:
        preset_entry["label"] = preset.label
        preset_entry["cpu"] = preset.cpu_display
        preset_entry["memory"] = preset.memory_display
        preset_entry["disk"] = preset.disk_display

    next_version = 1
    if preset_entry["versions"]:
        next_version = max(entry["version"] for entry in preset_entry["versions"]) + 1

    preset_entry["versions"].append(
        {
            "version": next_version,
            "snapshotId": snapshot_id,
            "capturedAt": captured_at,
        }
    )
    preset_entry["versions"].sort(key=lambda entry: entry["version"])

    updated_manifest["schemaVersion"] = CURRENT_MANIFEST_SCHEMA_VERSION
    updated_manifest["updatedAt"] = captured_at
    return updated_manifest


# ---------------------------------------------------------------------------
# Preset helpers
# ---------------------------------------------------------------------------


def _render_verification_table(
    results: list[SnapshotRunResult],
    console: Console,
) -> None:
    if not results:
        return
    headers = (
        "Preset",
        "CPU",
        "Memory",
        "Disk",
        "VS Code URL",
        "VNC URL",
    )
    rows: list[tuple[str, ...]] = [headers]
    for result in results:
        rows.append(
            (
                result.preset.preset_id,
                result.preset.cpu_display,
                result.preset.memory_display,
                result.preset.disk_display,
                result.vscode_url,
                result.vnc_url,
            )
        )
    col_widths = [max(len(row[idx]) for row in rows) for idx in range(len(headers))]
    console.always("\nSnapshot verification URLs:")
    for row in rows:
        line_parts: list[str] = []
        for idx, cell in enumerate(row):
            width = col_widths[idx]
            line_parts.append(cell.ljust(width))
        console.always("  " + "  |  ".join(line_parts))


async def _prompt_verification_for_preset(
    preset_id: str,
    vscode_url: str,
    vnc_url: str,
    console: Console,
) -> None:
    console.always(
        f"\nVerify preset {preset_id} (VS Code: {vscode_url}, VNC: {vnc_url})"
    )
    console.always("Press Enter after verification to proceed with snapshotting.")
    await asyncio.to_thread(input, "")


def _format_cpu_display(vcpus: int) -> str:
    return f"{vcpus} vCPU"


def _format_memory_display(memory_mib: int) -> str:
    memory_gb = max(memory_mib // 1024, 1)
    return f"{memory_gb} GB RAM"


def _format_disk_display(disk_size_mib: int) -> str:
    disk_gb = max(disk_size_mib // 1024, 1)
    return f"{disk_gb} GB SSD"


def _preset_id_from_resources(
    vcpus: int,
    memory_mib: int,
    disk_size_mib: int,
) -> str:
    memory_gb = max(memory_mib // 1024, 1)
    disk_gb = max(disk_size_mib // 1024, 1)
    return f"{vcpus}vcpu_{memory_gb}gb_{disk_gb}gb"


def _build_preset_plans(args: argparse.Namespace) -> tuple[SnapshotPresetPlan, ...]:
    standard_plan = SnapshotPresetPlan(
        preset_id=_preset_id_from_resources(
            args.standard_vcpus, args.standard_memory, args.standard_disk_size
        ),
        label="Standard workspace",
        cpu_display=_format_cpu_display(args.standard_vcpus),
        memory_display=_format_memory_display(args.standard_memory),
        disk_display=_format_disk_display(args.standard_disk_size),
        vcpus=args.standard_vcpus,
        memory_mib=args.standard_memory,
        disk_size_mib=args.standard_disk_size,
    )
    boosted_plan = SnapshotPresetPlan(
        preset_id=_preset_id_from_resources(
            args.boosted_vcpus, args.boosted_memory, args.boosted_disk_size
        ),
        label="Performance workspace",
        cpu_display=_format_cpu_display(args.boosted_vcpus),
        memory_display=_format_memory_display(args.boosted_memory),
        disk_display=_format_disk_display(args.boosted_disk_size),
        vcpus=args.boosted_vcpus,
        memory_mib=args.boosted_memory,
        disk_size_mib=args.boosted_disk_size,
    )
    return (standard_plan, boosted_plan)


def _build_resource_profile(
    vcpus: int,
    memory_mib: int,
) -> ResourceProfile:
    cpu_period = 100_000
    cpu_quota: int | None = None
    if vcpus > 0:
        cpu_quota = max(int(vcpus * cpu_period * 0.9), cpu_period)

    memory_high: int | None = None
    memory_max: int | None = None
    memory_bytes = memory_mib * 1024 * 1024
    if memory_bytes > 0:
        memory_high = max(memory_bytes * 9 // 10, 1)
        memory_max = max(memory_bytes * 95 // 100, memory_high)

    return ResourceProfile(
        name="cmux-provision",
        cpu_quota=cpu_quota,
        cpu_period=cpu_quota and cpu_period,
        cpu_weight=80,
        memory_high=memory_high,
        memory_max=memory_max,
        io_weight=200,
    )


# ---------------------------------------------------------------------------
# Notifications
# ---------------------------------------------------------------------------


def send_macos_notification(console: Console, title: str, message: str) -> None:
    if sys.platform != "darwin":
        return
    if shutil.which("osascript") is None:
        return
    script = f"display notification {json.dumps(message, ensure_ascii=False)} with title {json.dumps(title, ensure_ascii=False)}"
    try:
        subprocess.run(["osascript", "-e", script], check=False)
    except Exception as exc:
        console.info(f"Failed to send macOS notification: {exc}")


def send_scary_notification(message: str) -> None:
    if sys.platform != "darwin":
        return
    if shutil.which("osascript") is None:
        return
    script = textwrap.dedent(
        f"""
        display notification {json.dumps(message, ensure_ascii=False)} with title "cmux snapshot failed"
        """
    ).strip()
    try:
        subprocess.run(["osascript", "-e", script], check=False)
    except Exception:
        pass


# ---------------------------------------------------------------------------
# Git / repo helpers
# ---------------------------------------------------------------------------


def _exec_git(repo_root: Path, args: list[str]) -> str | None:
    env = dict(os.environ)
    env.setdefault("LC_ALL", "C")
    git_candidates = [env.get("GIT_EXE"), env.get("GIT_BINARY"), "git"]
    errors: list[str] = []
    for candidate in git_candidates:
        if not candidate:
            continue
        try:
            completed = subprocess.run(
                [candidate, *args],
                cwd=str(repo_root),
                env=env,
                check=False,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
            )
        except FileNotFoundError:
            errors.append(f"{candidate}: not found")
            continue
        if completed.returncode == 0:
            return completed.stdout
        errors.append(
            completed.stderr.strip() or f"{candidate}: exit code {completed.returncode}"
        )
    if errors:
        raise RuntimeError(f"git command {' '.join(args)} failed: {'; '.join(errors)}")
    return None


def list_repo_files(repo_root: Path) -> list[Path]:
    output = _exec_git(
        repo_root,
        ["ls-files", "--cached", "--others", "--exclude-standard", "-z"],
    )
    if output is None:
        files: list[Path] = []
        for path in repo_root.rglob("*"):
            if path.is_file() and ".git" not in path.parts:
                files.append(path.relative_to(repo_root))
        return files
    entries = [entry for entry in output.split("\0") if entry]
    return [Path(entry) for entry in entries]


def create_repo_archive(repo_root: Path) -> Path:
    files = list_repo_files(repo_root)
    tmp = tempfile.NamedTemporaryFile(prefix="cmux-repo-", suffix=".tar", delete=False)
    tmp_path = Path(tmp.name)
    tmp.close()
    with tarfile.open(tmp_path, "w") as tar:
        for rel_path in files:
            full_path = repo_root / rel_path
            if not full_path.exists():
                continue
            tar.add(full_path, arcname=str(rel_path))
    return tmp_path


# ---------------------------------------------------------------------------
# Instance helpers
# ---------------------------------------------------------------------------


async def _expose_standard_ports(
    instance: Instance,
    console: Console,
) -> dict[int, str]:
    ports = [
        EXEC_HTTP_PORT,
        39377,
        VSCODE_HTTP_PORT,
        39379,
        XTERM_HTTP_PORT,
        VNC_HTTP_PORT,
        CDP_HTTP_PORT,
    ]
    console.info("Exposing standard HTTP services...")

    async def _expose(port: int) -> tuple[int, str]:
        url = await instance.aexpose_http_service(name=f"port-{port}", port=port)
        return port, url

    exposed = await asyncio.gather(*(_expose(port) for port in ports))
    mapping: dict[int, str] = {}
    for port, url in exposed:
        console.info(f"Exposed port {port} â†’ {url}")
        mapping[port] = url
    return mapping


async def _await_instance_ready(instance: Instance, *, console: Console) -> None:
    console.info(f"Waiting for instance {instance.id} to become ready...")
    await instance.await_until_ready()
    console.info(f"Instance {instance.id} is ready")


def _stop_instance(instance: Instance, console: Console) -> None:
    try:
        console.info(f"Stopping instance {instance.id}...")
        instance.stop()
        console.info(f"Instance {instance.id} stopped")
    except Exception as exc:
        console.always(f"Failed to stop instance {instance.id}: {exc}")


# ---------------------------------------------------------------------------
# Exec binary build and setup
# ---------------------------------------------------------------------------


def _parse_go_target(target: str) -> tuple[str, str]:
    normalized = target.lower().strip()
    prefixes = ("bun-", "go-", "golang-")
    for prefix in prefixes:
        if normalized.startswith(prefix):
            normalized = normalized[len(prefix) :]
            break
    normalized = normalized.replace("-", "/").replace("_", "/")
    parts = [part for part in normalized.split("/") if part]
    if len(parts) < 2:
        raise ValueError(f"invalid Go target '{target}', expected format GOOS/GOARCH")
    goos, goarch = parts[0], parts[1]
    architecture_aliases = {
        "x64": "amd64",
        "x86_64": "amd64",
        "amd64": "amd64",
        "arm64": "arm64",
        "aarch64": "arm64",
    }
    goarch = architecture_aliases.get(goarch, goarch)
    return goos, goarch


def _build_exec_binary_sync(repo_root: Path, console: Console) -> Path:
    go = shutil.which("go")
    if go is None:
        raise RuntimeError(
            "Go toolchain not found in PATH. Install Go to build the exec daemon."
        )
    entry_path = repo_root / EXEC_SOURCE_PATH
    if not entry_path.exists():
        raise FileNotFoundError(
            f"exec daemon entrypoint not found at {entry_path}. "
            "Did you run this from the repository root?"
        )
    target = os.environ.get(EXEC_BUILD_TARGET_ENV, DEFAULT_EXEC_BUILD_TARGET)
    try:
        goos, goarch = _parse_go_target(target)
    except ValueError as exc:
        raise RuntimeError(str(exc)) from exc
    output_dir = repo_root / EXEC_BUILD_OUTPUT_DIR
    output_dir.mkdir(parents=True, exist_ok=True)
    binary_path = (output_dir / EXEC_BINARY_NAME).resolve()
    console.info(
        f"Building {EXEC_BINARY_NAME} with Go (GOOS={goos}, GOARCH={goarch}) "
        f"from {EXEC_SOURCE_PATH}..."
    )
    env = dict(os.environ)
    env.update(
        {
            "GOOS": goos,
            "GOARCH": goarch,
            "CGO_ENABLED": "0",
        }
    )
    command = [
        go,
        "build",
        "-o",
        str(binary_path),
        ".",
    ]
    result = subprocess.run(command, cwd=str(entry_path.parent), env=env, check=False)
    if result.returncode != 0:
        raise RuntimeError(
            f"failed to build {EXEC_BINARY_NAME} (go exit {result.returncode})"
        )
    if not binary_path.exists():
        raise FileNotFoundError(
            f"expected exec binary at {binary_path}, but it was not produced"
        )
    console.info(f"Built exec binary at {binary_path}")
    return binary_path


async def setup_exec_service(
    ctx: TaskContext,
    *,
    binary_path: Path,
    service_url: str,
) -> HttpExecClient:
    ctx.console.info("Uploading exec service binary...")
    upload_attempts = 0
    while True:
        try:
            await ctx.instance.aupload(str(binary_path), EXEC_TEMP_PATH)
            break
        except (ApiError, httpx.HTTPError, paramiko.SSHException, OSError) as exc:
            upload_attempts += 1
            if upload_attempts >= 5:
                raise
            delay = 1.5 * upload_attempts
            ctx.console.info(
                f"Retrying exec upload (attempt {upload_attempts}/5) after error: {exc}"
            )
            await asyncio.sleep(delay)
    remote_binary = shlex.quote(EXEC_REMOTE_PATH)
    remote_temp = shlex.quote(EXEC_TEMP_PATH)
    log_path = "/var/log/cmux-execd.log"
    await ctx.run_via_ssh(
        "verify-exec-upload",
        f"ls -l {remote_temp}",
        use_cgroup=False,
    )
    start_script = textwrap.dedent(
        f"""
        set -euo pipefail
        install -Dm0755 {remote_temp} {remote_binary}
        rm -f {remote_temp}
        if command -v pkill >/dev/null 2>&1; then
            pkill -x {EXEC_BINARY_NAME} || true
        else
            pids=$(ps -eo pid,comm | awk '$2 == "{EXEC_BINARY_NAME}" {{print $1}}')
            if [ -n "$pids" ]; then
                kill $pids || true
            fi
        fi
        mkdir -p /var/log
        nohup {remote_binary} --port {EXEC_HTTP_PORT} >{shlex.quote(log_path)} 2>&1 &
        if command -v pgrep >/dev/null 2>&1; then
            sleep 1
            if ! pgrep -x {EXEC_BINARY_NAME} >/dev/null 2>&1; then
                echo "cmux-execd failed to start" >&2
                if [ -f {shlex.quote(log_path)} ]; then
                    tail -n 50 {shlex.quote(log_path)} >&2 || true
                fi
                exit 1
            fi
        fi
        """
    )
    await ctx.run_via_ssh(
        "start-exec-service",
        start_script,
        use_cgroup=False,
    )
    client = HttpExecClient(service_url, ctx.console)
    await client.wait_ready(retries=30, delay=0.5)
    ctx.exec_client = client
    ctx.console.info("Exec service ready")
    return client


# ---------------------------------------------------------------------------
# Task registry and task definitions
# ---------------------------------------------------------------------------

dotenv.load_dotenv()

registry = TaskRegistry()


@registry.task(
    name="build-setup-exec-binary",
    description="Build and setup exec binary",
)
async def build_exec_binary(ctx: TaskContext) -> None:
    repo_root = ctx.repo_root
    console = ctx.console
    ctx.console.info("Building exec binary...")
    exec_binary_path = await asyncio.to_thread(_build_exec_binary_sync, repo_root, console)
    ctx.console.info("Built exec binary")

    ctx.console.info(f"Setting up exec service at {ctx.exec_service_url}")
    await setup_exec_service(ctx, binary_path=exec_binary_path, service_url=ctx.exec_service_url)
    ctx.console.info("Exec service setup complete")


@registry.task(
    name="configure-provisioning-cgroup",
    description="Configure provisioning cgroup",
)
async def configure_provisioning_cgroup(ctx: TaskContext) -> None:
    ctx.console.info("Configuring provisioning cgroup...")
    profile = ctx.resource_profile
    if profile is None:
        ctx.console.info("Resource profile not provided; skipping cgroup configuration")
        return

    cgroup_path = f"/sys/fs/cgroup/{profile.name}"
    quoted_cgroup_path = shlex.quote(cgroup_path)
    cpu_max_value = (
        f"{profile.cpu_quota} {profile.cpu_period}"
        if profile.cpu_quota is not None and profile.cpu_period is not None
        else ""
    )
    cpu_quota_value = str(profile.cpu_quota) if profile.cpu_quota is not None else ""
    cpu_period_value = str(profile.cpu_period) if profile.cpu_period is not None else ""
    cpu_weight_value = str(profile.cpu_weight) if profile.cpu_weight is not None else ""
    memory_high_value = (
        str(profile.memory_high) if profile.memory_high is not None else ""
    )
    memory_max_value = str(profile.memory_max) if profile.memory_max is not None else ""
    io_weight_value = str(profile.io_weight) if profile.io_weight is not None else ""

    script = textwrap.dedent(
        f"""
        set -euo pipefail
        CG_ROOT="/sys/fs/cgroup"
        if [ -f "${{CG_ROOT}}/cgroup.controllers" ]; then
            TARGET={quoted_cgroup_path}
            mkdir -p "${{TARGET}}"
            controllers="$(cat "${{CG_ROOT}}/cgroup.controllers")"
            enable_controller() {{
                local ctrl="$1"
                if printf '%s' "${{controllers}}" | grep -qw "$ctrl"; then
                    if ! grep -qw "$ctrl" "${{CG_ROOT}}/cgroup.subtree_control"; then
                        echo "+$ctrl" > "${{CG_ROOT}}/cgroup.subtree_control" || true
                    fi
                fi
            }}
            enable_controller cpu
            enable_controller io
            enable_controller memory
            if [ -n "{cpu_max_value}" ] && [ -w "${{TARGET}}/cpu.max" ]; then
                echo "{cpu_max_value}" > "${{TARGET}}/cpu.max"
            fi
            if [ -n "{cpu_weight_value}" ] && [ -w "${{TARGET}}/cpu.weight" ]; then
                echo "{cpu_weight_value}" > "${{TARGET}}/cpu.weight"
            fi
            if [ -n "{memory_high_value}" ] && [ -w "${{TARGET}}/memory.high" ]; then
                echo "{memory_high_value}" > "${{TARGET}}/memory.high"
            fi
            if [ -n "{memory_max_value}" ] && [ -w "${{TARGET}}/memory.max" ]; then
                echo "{memory_max_value}" > "${{TARGET}}/memory.max"
            fi
            if [ -n "{io_weight_value}" ] && [ -w "${{TARGET}}/io.weight" ]; then
                echo "{io_weight_value}" > "${{TARGET}}/io.weight"
            fi
            exit 0
        fi
        if command -v cgcreate >/dev/null 2>&1 && command -v cgset >/dev/null 2>&1; then
            cgcreate -g cpu,memory,blkio:{profile.name} || true
            if [ -n "{cpu_period_value}" ] && [ -n "{cpu_quota_value}" ]; then
                cgset -r cpu.cfs_period_us={cpu_period_value} {profile.name} || true
                cgset -r cpu.cfs_quota_us={cpu_quota_value} {profile.name} || true
            fi
            if [ -n "{memory_max_value}" ]; then
                cgset -r memory.limit_in_bytes={memory_max_value} {profile.name} || true
            fi
            if [ -n "{memory_high_value}" ]; then
                cgset -r memory.soft_limit_in_bytes={memory_high_value} {profile.name} || true
            fi
            if [ -n "{io_weight_value}" ]; then
                cgset -r blkio.weight={io_weight_value} {profile.name} || true
            fi
        fi
        exit 0
        """
    )
    await ctx.run("configure-resource-cgroup", script)
    verification = await ctx.run(
        "verify-resource-cgroup",
        textwrap.dedent(
            f"""
            if [ -d {quoted_cgroup_path} ] && [ -f {quoted_cgroup_path}/cgroup.procs ]; then
                echo ready
            fi
            """
        ),
    )
    if (verification.stdout or "").strip() == "ready":
        ctx.cgroup_path = cgroup_path
        ctx.console.info(f"Resource cgroup active at {cgroup_path}")
    else:
        ctx.console.info(
            "Cgroup controllers unavailable; continuing without resource isolation"
        )


@registry.task(
    name="apt-bootstrap",
    description="Install core apt utilities and set up package sources",
)
async def task_apt_bootstrap(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        set -eux

        # Configure APT for parallel downloads (16 parallel to saturate 2gbps)
        cat > /etc/apt/apt.conf.d/99parallel << 'EOF'
        Acquire::Queue-Mode "host";
        APT::Acquire::Max-Parallel-Downloads "16";
        Acquire::http::Pipeline-Depth "10";
        Acquire::https::Pipeline-Depth "10";
        EOF

        # Update and install core utilities needed for source setup
        DEBIAN_FRONTEND=noninteractive apt-get update
        DEBIAN_FRONTEND=noninteractive apt-get install -y \
            ca-certificates curl wget jq git gnupg lsb-release \
            tar unzip xz-utils zip bzip2 gzip htop lsof

        # Setup GitHub CLI repository
        install -m 0755 -d /usr/share/keyrings
        curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg \
            | dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg
        chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg
        arch="$(dpkg --print-architecture)"
        echo "deb [arch=${arch} signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" \
            > /etc/apt/sources.list.d/github-cli.list

        rm -rf /var/lib/apt/lists/*
        """
    )
    await ctx.run("apt-bootstrap", cmd)


@registry.task(
    name="install-base-packages",
    deps=("apt-bootstrap",),
    description="Install build-essential tooling and utilities",
)
async def task_install_base_packages(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        set -eux

        # Single apt-get update to pick up all configured sources
        DEBIAN_FRONTEND=noninteractive apt-get update

        # Install all packages in parallel in a single command
        DEBIAN_FRONTEND=noninteractive apt-get install -y \
            build-essential make pkg-config g++ libssl-dev \
            ruby-full perl software-properties-common \
            tigervnc-standalone-server tigervnc-common \
            xvfb \
            x11-xserver-utils xterm novnc \
            dbus-x11 openbox \
            tmux \
            gh \
            zsh \
            zsh-autosuggestions \
            ripgrep ffmpeg xdotool


        # Download and install Chrome
        arch="$(dpkg --print-architecture)"
        case "${arch}" in
          amd64)
            chrome_url="https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb"
            ;;
          arm64)
            chrome_url="https://dl.google.com/linux/direct/google-chrome-stable_current_arm64.deb"
            ;;
          *)
            echo "Unsupported architecture: ${arch}" >&2
            exit 1
            ;;
        esac
        cd /tmp
        curl -fsSL -o chrome.deb "${chrome_url}"
        DEBIAN_FRONTEND=noninteractive apt-get install -y ./chrome.deb || true
        DEBIAN_FRONTEND=noninteractive apt-get install -yf
        rm -f chrome.deb

        # Clean up
        rm -rf /var/lib/apt/lists/*
        """
    )
    await ctx.run("install-base-packages", cmd)


@registry.task(
    name="ensure-docker",
    deps=("install-base-packages",),
    description="Install Docker engine and CLI plugins",
)
async def task_ensure_docker(ctx: TaskContext) -> None:
    install_cmd = textwrap.dedent(
        """
        set -euo pipefail

        echo "[docker] ensuring Docker APT repository"
        DEBIAN_FRONTEND=noninteractive apt-get update
        DEBIAN_FRONTEND=noninteractive apt-get install -y ca-certificates curl
        os_release="/etc/os-release"
        if [ ! -f "$os_release" ]; then
          echo "Missing /etc/os-release; unable to determine distribution" >&2
          exit 1
        fi
        . "$os_release"
        distro_codename="${UBUNTU_CODENAME:-${VERSION_CODENAME:-stable}}"
        distro_id="${ID:-debian}"
        case "$distro_id" in
          ubuntu|Ubuntu|UBUNTU)
            repo_id="ubuntu"
            ;;
          debian|Debian|DEBIAN)
            repo_id="debian"
            ;;
          *)
            echo "Unrecognized distro id '$distro_id'; defaulting to debian" >&2
            repo_id="debian"
            ;;
        esac
        install -m 0755 -d /etc/apt/keyrings
        curl -fsSL "https://download.docker.com/linux/${repo_id}/gpg" -o /etc/apt/keyrings/docker.asc
        chmod a+r /etc/apt/keyrings/docker.asc
        printf 'deb [arch=%s signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/%s %s stable\\n' \
          "$(dpkg --print-architecture)" "$repo_id" "$distro_codename" \
          > /etc/apt/sources.list.d/docker.list

        echo "[docker] installing engine and CLI plugins"
        DEBIAN_FRONTEND=noninteractive apt-get update
        DEBIAN_FRONTEND=noninteractive apt-get install -y \
          docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

        systemctl enable docker.service
        systemctl enable docker.socket || true
        systemctl start docker.service

        for attempt in $(seq 1 30); do
          if docker info >/dev/null 2>&1; then
            echo "[docker] daemon is ready"
            break
          fi
          if [ "$attempt" -eq 30 ]; then
            echo "[docker] daemon failed to start within expected window" >&2
            exit 1
          fi
          sleep 2
        done

        docker --version
        docker compose version
        docker buildx version
        docker run --rm hello-world
        """
    )
    await ctx.run("ensure-docker-install", install_cmd)


@registry.task(
    name="install-node-runtime",
    deps=("install-base-packages",),
    description="Install Node.js runtime and pnpm via corepack",
)
async def task_install_node(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        set -eux
        NODE_VERSION="24.9.0"
        arch="$(uname -m)"
        case "${arch}" in
          x86_64) node_arch="x64" ;;
          aarch64|arm64) node_arch="arm64" ;;
          *) echo "Unsupported architecture: ${arch}" >&2; exit 1 ;;
        esac
        tmp_dir="$(mktemp -d)"
        trap 'rm -rf "${tmp_dir}"' EXIT
        cd "${tmp_dir}"
        curl -fsSLO "https://nodejs.org/dist/v${NODE_VERSION}/node-v${NODE_VERSION}-linux-${node_arch}.tar.xz"
        curl -fsSLO "https://nodejs.org/dist/v${NODE_VERSION}/SHASUMS256.txt"
        grep " node-v${NODE_VERSION}-linux-${node_arch}.tar.xz$" SHASUMS256.txt | sha256sum -c -
        tar -xJf "node-v${NODE_VERSION}-linux-${node_arch}.tar.xz" -C /usr/local --strip-components=1
        cd /
        ln -sf /usr/local/bin/node /usr/bin/node
        ln -sf /usr/local/bin/npm /usr/bin/npm
        ln -sf /usr/local/bin/npx /usr/bin/npx
        ln -sf /usr/local/bin/corepack /usr/bin/corepack
        npm install -g node-gyp
        corepack enable
        corepack prepare pnpm@10.14.0 --activate
        """
    )
    await ctx.run("install-node-runtime", cmd)


@registry.task(
    name="install-nvm",
    deps=("install-node-runtime",),
    description="Install nvm for runtime use",
)
async def task_install_nvm(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        set -eux
        export NVM_DIR="/root/.nvm"
        mkdir -p "${NVM_DIR}"
        curl -fsSL "https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh" | bash
        cat <<'PROFILE' > /etc/profile.d/nvm.sh
        export NVM_DIR="$HOME/.nvm"
        [ -s "$NVM_DIR/nvm.sh" ] && . "$NVM_DIR/nvm.sh"
        [ -s "$NVM_DIR/bash_completion" ] && . "$NVM_DIR/bash_completion"
        PROFILE
        bash -lc 'source /etc/profile.d/nvm.sh && nvm --version'
        """
    )
    await ctx.run("install-nvm", cmd)


@registry.task(
    name="install-bun",
    deps=("install-base-packages",),
    description="Install Bun runtime",
)
async def task_install_bun(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        curl -fsSL https://bun.sh/install | bash
        install -m 0755 /root/.bun/bin/bun /usr/local/bin/bun
        ln -sf /usr/local/bin/bun /usr/local/bin/bunx
        bun --version
        bunx --version
        """
    )
    await ctx.run("install-bun", cmd)


@registry.task(
    name="install-go-toolchain",
    deps=("install-base-packages",),
    description="Install Go toolchain for building CMux helpers",
)
async def task_install_go_toolchain(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        set -eux
        GO_VERSION="1.25.2"
        ARCH="$(uname -m)"
        case "${ARCH}" in
          x86_64)
            GO_ARCH="amd64"
            ;;
          aarch64|arm64)
            GO_ARCH="arm64"
            ;;
          *)
            echo "Unsupported architecture for Go: ${ARCH}" >&2
            exit 1
            ;;
        esac
        TMP_DIR="$(mktemp -d)"
        trap 'rm -rf "${TMP_DIR}"' EXIT
        cd "${TMP_DIR}"
        curl -fsSLo go.tar.gz "https://go.dev/dl/go${GO_VERSION}.linux-${GO_ARCH}.tar.gz"
        rm -rf /usr/local/go
        tar -C /usr/local -xzf go.tar.gz
        install -d /usr/local/bin
        install -d -m 0755 /usr/local/go-workspace/bin
        install -d -m 0755 /usr/local/go-workspace/pkg/mod
        install -d -m 0755 /usr/local/go-workspace/pkg/sumdb
        install -d -m 0755 /usr/local/go-cache
        ln -sf /usr/local/go/bin/go /usr/local/bin/go
        ln -sf /usr/local/go/bin/gofmt /usr/local/bin/gofmt
        /usr/local/go/bin/go version
        """
    )
    await ctx.run("install-go-toolchain", cmd)


@registry.task(
    name="install-uv-python",
    deps=("apt-bootstrap",),
    description="Install uv CLI and provision default Python runtime",
)
async def task_install_uv_python(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        set -eux
        ARCH="$(uname -m)"
        curl -LsSf https://astral.sh/uv/install.sh | sh
        export PATH="${HOME}/.local/bin:/usr/local/cargo/bin:${PATH}"
        uv python install --default
        PIP_VERSION="$(curl -fsSL https://pypi.org/pypi/pip/json | jq -r '.info.version')"
        python3 -m pip install --break-system-packages --upgrade "pip==${PIP_VERSION}"
        ln -sf /usr/bin/python3 /usr/bin/python
        """
    )
    await ctx.run("install-uv-python", cmd)


@registry.task(
    name="install-rust-toolchain",
    deps=("install-base-packages",),
    description="Install Rust toolchain via rustup",
)
async def task_install_rust_toolchain(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        set -eux
        export RUSTUP_HOME=/usr/local/rustup
        export CARGO_HOME=/usr/local/cargo
        install -d -m 0755 "${RUSTUP_HOME}" "${CARGO_HOME}"
        install -d -m 0755 "${CARGO_HOME}/bin"
        export PATH="${CARGO_HOME}/bin:${PATH}"
        ARCH="$(uname -m)"
        case "${ARCH}" in
          x86_64)
            RUST_HOST_TARGET="x86_64-unknown-linux-gnu"
            ;;
          aarch64|arm64)
            RUST_HOST_TARGET="aarch64-unknown-linux-gnu"
            ;;
          *)
            echo "Unsupported architecture: ${ARCH}" >&2
            exit 1
            ;;
        esac
        curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | \
          sh -s -- -y --no-modify-path --profile minimal
        source "${CARGO_HOME}/env"
        rustup component add rustfmt
        rustup target add "${RUST_HOST_TARGET}"
        rustup default stable
        """
    )
    await ctx.run("install-rust-toolchain", cmd)


@registry.task(
    name="install-openvscode",
    deps=("apt-bootstrap",),
    description="Install OpenVSCode server",
)
async def task_install_openvscode(ctx: TaskContext) -> None:
    if get_ide_provider() != IDE_PROVIDER_OPENVSCODE:
        ctx.console.info("Skipping install-openvscode (IDE provider is not openvscode)")
        return
    cmd = textwrap.dedent(
        """
        set -eux
        CODE_RELEASE="$(curl -fsSL https://api.github.com/repos/gitpod-io/openvscode-server/releases/latest | jq -r '.tag_name' | sed 's|^openvscode-server-v||')"
        arch="$(dpkg --print-architecture)"
        case "${arch}" in
          amd64) ARCH="x64" ;;
          arm64) ARCH="arm64" ;;
          *) echo "Unsupported architecture ${arch}" >&2; exit 1 ;;
        esac
        mkdir -p /app/openvscode-server
        url="https://github.com/gitpod-io/openvscode-server/releases/download/openvscode-server-v${CODE_RELEASE}/openvscode-server-v${CODE_RELEASE}-linux-${ARCH}.tar.gz"
        curl -fSL --retry 6 --retry-all-errors --retry-delay 2 --connect-timeout 20 --max-time 600 -o /tmp/openvscode-server.tar.gz "${url}" || \
          curl -fSL4 --retry 6 --retry-all-errors --retry-delay 2 --connect-timeout 20 --max-time 600 -o /tmp/openvscode-server.tar.gz "${url}"
        tar xf /tmp/openvscode-server.tar.gz -C /app/openvscode-server --strip-components=1
        rm -f /tmp/openvscode-server.tar.gz
        """
    )
    await ctx.run("install-openvscode", cmd)


@registry.task(
    name="install-coder",
    deps=("apt-bootstrap",),
    description="Install Coder (code-server)",
)
async def task_install_coder(ctx: TaskContext) -> None:
    if get_ide_provider() != IDE_PROVIDER_CODER:
        ctx.console.info("Skipping install-coder (IDE provider is not coder)")
        return
    cmd = textwrap.dedent(
        """
        set -eux
        CODER_RELEASE="$(curl -fsSL https://api.github.com/repos/coder/code-server/releases/latest | jq -r '.tag_name' | sed 's|^v||')"
        arch="$(dpkg --print-architecture)"
        case "${arch}" in
          amd64) ARCH="amd64" ;;
          arm64) ARCH="arm64" ;;
          *) echo "Unsupported architecture ${arch}" >&2; exit 1 ;;
        esac
        mkdir -p /app/code-server
        url="https://github.com/coder/code-server/releases/download/v${CODER_RELEASE}/code-server-${CODER_RELEASE}-linux-${ARCH}.tar.gz"
        curl -fSL --retry 6 --retry-all-errors --retry-delay 2 --connect-timeout 20 --max-time 600 -o /tmp/code-server.tar.gz "${url}" || \
          curl -fSL4 --retry 6 --retry-all-errors --retry-delay 2 --connect-timeout 20 --max-time 600 -o /tmp/code-server.tar.gz "${url}"
        tar xf /tmp/code-server.tar.gz -C /app/code-server --strip-components=1
        rm -f /tmp/code-server.tar.gz

        # Create code-server config directory and config.yaml
        mkdir -p /root/.config/code-server
        cat > /root/.config/code-server/config.yaml << 'EOF'
bind-addr: 0.0.0.0:39378
auth: none
cert: false
EOF

        # Create code-server user settings
        mkdir -p /root/.code-server/User
        cat > /root/.code-server/User/settings.json << 'EOF'
{
  "workbench.startupEditor": "none",
  "security.workspace.trust.enabled": false,
  "editor.formatOnSave": true,
  "editor.formatOnSaveMode": "file",
  "files.autoSave": "afterDelay",
  "files.autoSaveDelay": 0
}
EOF
        """
    )
    await ctx.run("install-coder", cmd)


@registry.task(
    name="install-cmux-code",
    deps=("apt-bootstrap",),
    description="Install Cmux Code (VSCode fork with OpenVSIX)",
)
async def task_install_cmux_code(ctx: TaskContext) -> None:
    if get_ide_provider() != IDE_PROVIDER_CMUX_CODE:
        ctx.console.info("Skipping install-cmux-code (IDE provider is not cmux-code)")
        return
    cmd = textwrap.dedent(
        """
        set -eux
        CODE_RELEASE="$(curl -fsSL https://api.github.com/repos/manaflow-ai/vscode-1/releases/latest | jq -r '.tag_name' | sed 's|^v||')"
        arch="$(dpkg --print-architecture)"
        case "${arch}" in
          amd64) ARCH="x64" ;;
          arm64) ARCH="arm64" ;;
          *) echo "Unsupported architecture ${arch}" >&2; exit 1 ;;
        esac
        mkdir -p /app/cmux-code
        url="https://github.com/manaflow-ai/vscode-1/releases/download/v${CODE_RELEASE}/vscode-server-linux-${ARCH}-web.tar.gz"
        curl -fSL --retry 6 --retry-all-errors --retry-delay 2 --connect-timeout 20 --max-time 600 -o /tmp/cmux-code.tar.gz "${url}" || \
          curl -fSL4 --retry 6 --retry-all-errors --retry-delay 2 --connect-timeout 20 --max-time 600 -o /tmp/cmux-code.tar.gz "${url}"
        tar xf /tmp/cmux-code.tar.gz -C /app/cmux-code --strip-components=1
        rm -f /tmp/cmux-code.tar.gz

        # Create cmux-code user settings
        mkdir -p /root/.vscode-server-oss/data/User
        cat > /root/.vscode-server-oss/data/User/settings.json << 'EOF'
{
  "workbench.startupEditor": "none",
  "workbench.secondarySideBar.defaultVisibility": "hidden",
  "security.workspace.trust.enabled": false,
  "telemetry.telemetryLevel": "off",
  "update.mode": "none",
  "extensions.verifySignature": false,
  "editor.formatOnSave": true,
  "editor.formatOnSaveMode": "file",
  "files.autoSave": "afterDelay",
  "files.autoSaveDelay": 1000
}
EOF
        """
    )
    await ctx.run("install-cmux-code", cmd)


@registry.task(
    name="package-vscode-extension",
    deps=("install-repo-dependencies",),
    description="Package the cmux VS Code extension for installation",
)
async def task_package_vscode_extension(ctx: TaskContext) -> None:
    repo = shlex.quote(ctx.remote_repo_root)
    cmd = textwrap.dedent(
        f"""
        set -euo pipefail
        export PATH="/usr/local/bin:$PATH"
        cd {repo}/packages/vscode-extension
        bun run package
        latest_vsix="$(ls -1t cmux-vscode-extension-*.vsix 2>/dev/null | head -n 1)"
        if [ -z "${{latest_vsix}}" ] || [ ! -f "${{latest_vsix}}" ]; then
          echo "cmux VS Code extension package not found" >&2
          exit 1
        fi
        install -Dm0644 "${{latest_vsix}}" /tmp/cmux-vscode-extension.vsix
        """
    )
    await ctx.run("package-vscode-extension", cmd)


@registry.task(
    name="install-ide-extensions",
    deps=("install-openvscode", "install-coder", "install-cmux-code", "package-vscode-extension"),
    description="Preinstall language extensions for the IDE",
)
async def task_install_ide_extensions(ctx: TaskContext) -> None:
    ide_provider = get_ide_provider()
    if ide_provider == IDE_PROVIDER_CODER:
        server_root = "/app/code-server"
        bin_path = f"{server_root}/bin/code-server"
        extensions_dir = "/root/.code-server/extensions"
        user_data_dir = "/root/.code-server"
    elif ide_provider == IDE_PROVIDER_CMUX_CODE:
        server_root = "/app/cmux-code"
        bin_path = f"{server_root}/bin/code-server-oss"
        extensions_dir = "/root/.vscode-server-oss/extensions"
        user_data_dir = "/root/.vscode-server-oss/data"
    else:
        server_root = "/app/openvscode-server"
        bin_path = f"{server_root}/bin/openvscode-server"
        extensions_dir = "/root/.openvscode-server/extensions"
        user_data_dir = "/root/.openvscode-server/data"

    ide_deps_path = Path(__file__).resolve().parent.parent / "configs/ide-deps.json"
    try:
        ide_deps_raw = ide_deps_path.read_text(encoding="utf-8")
        ide_deps = json.loads(ide_deps_raw)
    except Exception as exc:
        raise RuntimeError(f"Failed to read {ide_deps_path}") from exc

    extensions = ide_deps.get("extensions")
    if not isinstance(extensions, list):
        raise RuntimeError("configs/ide-deps.json extensions must be an array.")

    extension_lines: list[str] = []
    for ext in extensions:
        if not isinstance(ext, dict):
            raise RuntimeError(f"Invalid extension entry {ext!r}")
        publisher = ext.get("publisher")
        name = ext.get("name")
        version = ext.get("version")
        if (
            not isinstance(publisher, str)
            or not isinstance(name, str)
            or not isinstance(version, str)
        ):
            raise RuntimeError(f"Invalid extension entry {ext!r}")
        extension_lines.append(f"{publisher}|{name}|{version}")

    if not extension_lines:
        raise RuntimeError("No extensions found in configs/ide-deps.json.")

    extensions_blob = "\n".join(extension_lines)

    cmd = textwrap.dedent(
        f"""
        set -eux
        export HOME=/root
        server_root="{server_root}"
        bin_path="{bin_path}"
        if [ ! -x "${{bin_path}}" ]; then
          echo "IDE binary not found at ${{bin_path}}" >&2
          exit 1
        fi
        extensions_dir="{extensions_dir}"
        user_data_dir="{user_data_dir}"
        mkdir -p "${{extensions_dir}}" "${{user_data_dir}}"
        cmux_vsix="/tmp/cmux-vscode-extension.vsix"
        if [ ! -f "${{cmux_vsix}}" ]; then
          echo "cmux extension package missing at ${{cmux_vsix}}" >&2
          exit 1
        fi
        install_from_file() {{
          local package_path="$1"
          "${{bin_path}}" \\
            --install-extension "${{package_path}}" \\
            --force \\
            --extensions-dir "${{extensions_dir}}" \\
            --user-data-dir "${{user_data_dir}}"
        }}
        install_from_file "${{cmux_vsix}}"
        rm -f "${{cmux_vsix}}"
        download_dir="$(mktemp -d)"
        cleanup() {{
          rm -rf "${{download_dir}}"
        }}
        trap cleanup EXIT
        download_extension() {{
          local publisher="$1"
          local name="$2"
          local version="$3"
          local destination="$4"
          local tmpfile="${{destination}}.download"
          local curl_stderr="${{tmpfile}}.stderr"
          local url="https://marketplace.visualstudio.com/_apis/public/gallery/publishers/${{publisher}}/vsextensions/${{name}}/${{version}}/vspackage"
          local attempt=1
          local max_attempts=3
          while [ "${{attempt}}" -le "${{max_attempts}}" ]; do
            if curl -fSL --retry 6 --retry-all-errors --retry-delay 2 --connect-timeout 20 --max-time 600 -o "${{tmpfile}}" "${{url}}" 2>"${{curl_stderr}}"; then
              rm -f "${{curl_stderr}}"
              break
            fi
            echo "Download attempt ${{attempt}}/${{max_attempts}} failed for ${{publisher}}.${{name}}@${{version}}; retrying..." >&2
            if [ -s "${{curl_stderr}}" ]; then
              cat "${{curl_stderr}}" >&2
            fi
            rm -f "${{tmpfile}}"
            attempt=$((attempt + 1))
            sleep $((attempt * 2))
          done
          if [ "${{attempt}}" -gt "${{max_attempts}}" ]; then
            echo "Failed to download ${{publisher}}.${{name}}@${{version}} after ${{max_attempts}} attempts" >&2
            if [ -s "${{curl_stderr}}" ]; then
              cat "${{curl_stderr}}" >&2
            fi
            rm -f "${{curl_stderr}}"
            return 1
          fi
          if gzip -t "${{tmpfile}}" >/dev/null 2>&1; then
            gunzip -c "${{tmpfile}}" > "${{destination}}"
            rm -f "${{tmpfile}}"
          else
            mv "${{tmpfile}}" "${{destination}}"
          fi
        }}
        while IFS='|' read -r publisher name version; do
          [ -z "${{publisher}}" ] && continue
          download_extension "${{publisher}}" "${{name}}" "${{version}}" "${{download_dir}}/${{publisher}}.${{name}}.vsix" &
        done <<'EXTENSIONS'
{extensions_blob}
EXTENSIONS
        wait
        set -- "${{download_dir}}"/*.vsix
        for vsix in "$@"; do
          if [ -f "${{vsix}}" ]; then
            install_from_file "${{vsix}}"
          fi
        done
        """
    )
    await ctx.run("install-ide-extensions", cmd)


@registry.task(
    name="install-cursor-cli",
    deps=("apt-bootstrap",),
    description="Install Cursor CLI",
)
async def task_install_cursor(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        curl https://cursor.com/install -fsS | bash
        /root/.local/bin/cursor-agent --version
        """
    )
    await ctx.run("install-cursor-cli", cmd)


@registry.task(
    name="install-global-cli",
    deps=("install-bun", "install-node-runtime"),
    description="Install global agent CLIs with bun",
)
async def task_install_global_cli(ctx: TaskContext) -> None:
    ide_deps_path = Path(__file__).resolve().parent.parent / "configs/ide-deps.json"
    try:
        ide_deps_raw = ide_deps_path.read_text(encoding="utf-8")
        ide_deps = json.loads(ide_deps_raw)
    except Exception as exc:
        raise RuntimeError(f"Failed to read {ide_deps_path}") from exc

    packages = ide_deps.get("packages")
    if not isinstance(packages, dict):
        raise RuntimeError("configs/ide-deps.json packages must be an object.")

    package_args: list[str] = []
    for name, version in packages.items():
        if not isinstance(name, str) or not isinstance(version, str):
            raise RuntimeError(f"Invalid package entry {name!r}: {version!r}")
        package_args.append(f"{name}@{version}")

    if not package_args:
        raise RuntimeError("No packages found in configs/ide-deps.json.")

    bun_line = "bun add -g " + " ".join(package_args)
    cmd = textwrap.dedent(
        f"""
        {bun_line}
        """
    )
    await ctx.run("install-global-cli", cmd)


@registry.task(
    name="setup-claude-oauth-wrappers",
    deps=("install-global-cli",),
    description="Create wrapper scripts for claude/npx/bunx to support OAuth token injection",
)
async def task_setup_claude_oauth_wrappers(ctx: TaskContext) -> None:
    """
    Create wrapper scripts that source /etc/claude-code/env before running claude-code.
    This allows cmux to inject CLAUDE_CODE_OAUTH_TOKEN at runtime without needing
    to set it as an environment variable (which doesn't work due to OAuth check timing).
    """
    script_path = Path(__file__).parent.parent / "configs" / "setup-claude-oauth-wrappers.sh"
    script_content = script_path.read_text()
    await ctx.run("setup-claude-oauth-wrappers", script_content)


@registry.task(
    name="configure-zsh",
    deps=("install-base-packages",),
    description="Install zsh configuration and default prompt",
)
async def task_configure_zsh(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        r"""
        set -eux
        zsh_path="$(command -v zsh)"
        if [ -z "${zsh_path}" ]; then
          echo "zsh not found" >&2
          exit 1
        fi
        current_shell="$(getent passwd root | cut -d: -f7 || true)"
        if [ "${current_shell}" != "${zsh_path}" ]; then
          if command -v chsh >/dev/null 2>&1; then
            chsh -s "${zsh_path}" root
          else
            usermod -s "${zsh_path}" root
          fi
        fi
        mkdir -p /root
        autosuggestions="/usr/share/zsh-autosuggestions/zsh-autosuggestions.zsh"
        cat > /root/.zshrc <<EOF
export SHELL="${zsh_path}"
export PATH="/usr/local/bin:/usr/local/cargo/bin:\$HOME/.local/bin:\$HOME/.bun/bin:\$PATH"
export XDG_RUNTIME_DIR="/run/user/0"
export NVM_DIR="\$HOME/.nvm"
if [ -s /etc/profile.d/nvm.sh ]; then
  . /etc/profile.d/nvm.sh
fi

alias code='/usr/local/bin/code'
alias c='code'
alias g='git'

autoload -Uz colors vcs_info
colors
setopt PROMPT_SUBST

zstyle ':vcs_info:*' enable git
zstyle ':vcs_info:*' check-for-changes true
zstyle ':vcs_info:git*:*' formats '%F{yellow}git:%b%f'
zstyle ':vcs_info:git*:*' actionformats '%F{yellow}git:%b*%f'

precmd() {
  vcs_info
}

PROMPT='%F{cyan}%n%f %F{green}%~%f\${vcs_info_msg_0_:+ \${vcs_info_msg_0_}} %# '
EOF
        if [ -f "${autosuggestions}" ]; then
          cat >> /root/.zshrc <<'EOF'

if [ -f "${autosuggestions}" ]; then
  source "${autosuggestions}"
  bindkey '^ ' autosuggest-accept
fi
EOF
        fi
        cat >> /root/.zshrc <<'EOF'
HISTFILE=~/.zsh_history
setopt HIST_IGNORE_DUPS HIST_VERIFY
EOF
        cat > /root/.zprofile <<'EOF'
[[ -f ~/.zshrc ]] && source ~/.zshrc
EOF
        mkdir -p /etc/profile.d
        cat <<'EOF' > /etc/profile.d/cmux-paths.sh
export RUSTUP_HOME=/usr/local/rustup
export CARGO_HOME=/usr/local/cargo
export PATH="/usr/local/bin:/usr/local/cargo/bin:$HOME/.local/bin:$HOME/.bun/bin:$PATH"
EOF
        if ! grep -q "alias g='git'" /root/.bashrc 2>/dev/null; then
          echo "alias g='git'" >> /root/.bashrc
        fi
        """
    )
    await ctx.run("configure-zsh", cmd)


@registry.task(
    name="configure-openbox",
    deps=("upload-repo", "install-base-packages"),
    description="Install openbox configuration for desktop menu",
)
async def task_configure_openbox(ctx: TaskContext) -> None:
    repo = shlex.quote(ctx.remote_repo_root)
    cmd = textwrap.dedent(
        f"""
        set -eux
        mkdir -p /root/.config/openbox
        install -Dm0644 {repo}/configs/openbox/menu.xml /root/.config/openbox/menu.xml
        """
    )
    await ctx.run("configure-openbox", cmd)


@registry.task(
    name="upload-repo",
    deps=("apt-bootstrap",),
    description="Upload repository to the instance",
)
async def task_upload_repo(ctx: TaskContext) -> None:
    archive = await asyncio.to_thread(create_repo_archive, ctx.repo_root)
    try:
        await ctx.instance.aupload(str(archive), ctx.remote_repo_tar)
        extract_cmd = textwrap.dedent(
            f"""
            rm -rf {shlex.quote(ctx.remote_repo_root)}
            mkdir -p {shlex.quote(ctx.remote_repo_root)}
            tar -xf {shlex.quote(ctx.remote_repo_tar)} -C {shlex.quote(ctx.remote_repo_root)}
            rm -f {shlex.quote(ctx.remote_repo_tar)}
            """
        )
        await ctx.run("extract-repo", extract_cmd)
    finally:
        archive.unlink(missing_ok=True)


@registry.task(
    name="install-repo-dependencies",
    deps=("upload-repo", "install-bun", "install-node-runtime"),
    description="Install workspace dependencies via bun",
)
async def task_install_repo_dependencies(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        f"""
        export PATH="/usr/local/bin:$PATH"
        cd {shlex.quote(ctx.remote_repo_root)}
        bun install --frozen-lockfile
        """
    )
    await ctx.run("install-repo-dependencies", cmd)


@registry.task(
    name="install-service-scripts",
    deps=("upload-repo", "install-base-packages"),
    description="Install VNC startup script (includes Chrome DevTools)",
)
async def task_install_service_scripts(ctx: TaskContext) -> None:
    repo = shlex.quote(ctx.remote_repo_root)
    cmd = textwrap.dedent(
        f"""
        install -d /usr/local/lib/cmux
        install -m 0755 {repo}/configs/systemd/bin/cmux-start-chrome /usr/local/lib/cmux/cmux-start-chrome
        install -m 0755 {repo}/configs/systemd/bin/cmux-manage-dockerd /usr/local/lib/cmux/cmux-manage-dockerd
        install -m 0755 {repo}/configs/systemd/bin/cmux-stop-dockerd /usr/local/lib/cmux/cmux-stop-dockerd
        install -m 0755 {repo}/configs/systemd/bin/cmux-configure-memory /usr/local/sbin/cmux-configure-memory
        """
    )
    await ctx.run("install-service-scripts", cmd)


@registry.task(
    name="build-cdp-proxy",
    deps=("install-service-scripts", "install-go-toolchain"),
    description="Build and install Chrome DevTools and VNC proxy binaries",
)
async def task_build_cdp_proxy(ctx: TaskContext) -> None:
    repo = shlex.quote(ctx.remote_repo_root)
    cmd = textwrap.dedent(
        f"""
        set -euo pipefail
        export PATH="/usr/local/go/bin:${{PATH}}"
        install -d /usr/local/lib/cmux
        cd {repo}/scripts/cdp-proxy
        go build -trimpath -o /usr/local/lib/cmux/{CDP_PROXY_BINARY_NAME} .
        if [ ! -x /usr/local/lib/cmux/{CDP_PROXY_BINARY_NAME} ]; then
          echo "Failed to build {CDP_PROXY_BINARY_NAME}" >&2
          exit 1
        fi
        cd {repo}/scripts/vnc-proxy
        go build -trimpath -o /usr/local/lib/cmux/{VNC_PROXY_BINARY_NAME} .
        if [ ! -x /usr/local/lib/cmux/{VNC_PROXY_BINARY_NAME} ]; then
          echo "Failed to build {VNC_PROXY_BINARY_NAME}" >&2
          exit 1
        fi
        """
    )
    await ctx.run("build-cdp-proxy", cmd)


@registry.task(
    name="install-systemd-units",
    deps=(
        "upload-repo",
        "install-ide-extensions",
        "install-service-scripts",
        "build-worker",
        "build-cdp-proxy",
        "link-rust-binaries",
        "configure-zsh",
    ),
    description="Install cmux systemd units and helpers",
)
async def task_install_systemd_units(ctx: TaskContext) -> None:
    repo = shlex.quote(ctx.remote_repo_root)
    ide_provider = get_ide_provider()

    # Determine IDE-specific service and configure script
    if ide_provider == IDE_PROVIDER_CODER:
        ide_service = "cmux-coder.service"
        ide_configure_script = "configure-coder"
        ide_env_file = "ide.env.coder"
    elif ide_provider == IDE_PROVIDER_CMUX_CODE:
        ide_service = "cmux-cmux-code.service"
        ide_configure_script = "configure-cmux-code"
        ide_env_file = "ide.env.cmux-code"
    else:
        ide_service = "cmux-openvscode.service"
        ide_configure_script = "configure-openvscode"
        ide_env_file = "ide.env.openvscode"

    cmd = textwrap.dedent(
        f"""
        set -euo pipefail

        install -d /usr/local/lib/cmux
        install -d /etc/cmux
        install -Dm0644 {repo}/configs/systemd/cmux.target /usr/lib/systemd/system/cmux.target
        install -Dm0644 {repo}/configs/systemd/{ide_service} /usr/lib/systemd/system/cmux-ide.service
        install -Dm0644 {repo}/configs/systemd/cmux-worker.service /usr/lib/systemd/system/cmux-worker.service
        install -Dm0644 {repo}/configs/systemd/cmux-proxy.service /usr/lib/systemd/system/cmux-proxy.service
        install -Dm0644 {repo}/configs/systemd/cmux-dockerd.service /usr/lib/systemd/system/cmux-dockerd.service
        install -Dm0644 {repo}/configs/systemd/cmux-devtools.service /usr/lib/systemd/system/cmux-devtools.service
        install -Dm0644 {repo}/configs/systemd/cmux-xvfb.service /usr/lib/systemd/system/cmux-xvfb.service
        install -Dm0644 {repo}/configs/systemd/cmux-tigervnc.service /usr/lib/systemd/system/cmux-tigervnc.service
        install -Dm0644 {repo}/configs/systemd/cmux-openbox.service /usr/lib/systemd/system/cmux-openbox.service
        install -Dm0644 {repo}/configs/systemd/cmux-vnc-proxy.service /usr/lib/systemd/system/cmux-vnc-proxy.service
        install -Dm0644 {repo}/configs/systemd/cmux-cdp-proxy.service /usr/lib/systemd/system/cmux-cdp-proxy.service
        install -Dm0644 {repo}/configs/systemd/cmux-pty.service /usr/lib/systemd/system/cmux-pty.service
        install -Dm0644 {repo}/configs/systemd/cmux-memory-setup.service /usr/lib/systemd/system/cmux-memory-setup.service
        install -Dm0755 {repo}/configs/systemd/bin/{ide_configure_script} /usr/local/lib/cmux/{ide_configure_script}
        install -Dm0644 {repo}/configs/systemd/{ide_env_file} /etc/cmux/ide.env
        install -Dm0755 {repo}/configs/systemd/bin/code /usr/local/bin/code
        touch /usr/local/lib/cmux/dockerd.flag
        mkdir -p /var/log/cmux
        mkdir -p /root/workspace
        mkdir -p /etc/systemd/system/multi-user.target.wants
        mkdir -p /etc/systemd/system/cmux.target.wants
        mkdir -p /etc/systemd/system/swap.target.wants
        ln -sf /usr/lib/systemd/system/cmux.target /etc/systemd/system/multi-user.target.wants/cmux.target
        ln -sf /usr/lib/systemd/system/cmux-ide.service /etc/systemd/system/cmux.target.wants/cmux-ide.service
        ln -sf /usr/lib/systemd/system/cmux-worker.service /etc/systemd/system/cmux.target.wants/cmux-worker.service
        ln -sf /usr/lib/systemd/system/cmux-proxy.service /etc/systemd/system/cmux.target.wants/cmux-proxy.service
        ln -sf /usr/lib/systemd/system/cmux-dockerd.service /etc/systemd/system/cmux.target.wants/cmux-dockerd.service
        ln -sf /usr/lib/systemd/system/cmux-devtools.service /etc/systemd/system/cmux.target.wants/cmux-devtools.service
        ln -sf /usr/lib/systemd/system/cmux-tigervnc.service /etc/systemd/system/cmux.target.wants/cmux-tigervnc.service
        ln -sf /usr/lib/systemd/system/cmux-openbox.service /etc/systemd/system/cmux.target.wants/cmux-openbox.service
        ln -sf /usr/lib/systemd/system/cmux-vnc-proxy.service /etc/systemd/system/cmux.target.wants/cmux-vnc-proxy.service
        ln -sf /usr/lib/systemd/system/cmux-cdp-proxy.service /etc/systemd/system/cmux.target.wants/cmux-cdp-proxy.service
        ln -sf /usr/lib/systemd/system/cmux-pty.service /etc/systemd/system/cmux.target.wants/cmux-pty.service
        ln -sf /usr/lib/systemd/system/cmux-memory-setup.service /etc/systemd/system/multi-user.target.wants/cmux-memory-setup.service
        ln -sf /usr/lib/systemd/system/cmux-memory-setup.service /etc/systemd/system/swap.target.wants/cmux-memory-setup.service
        {{ systemctl daemon-reload || true; }}
        {{ systemctl enable cmux.target || true; }}
        chown root:root /usr/local
        chown root:root /usr/local/bin
        chmod 0755 /usr/local
        chmod 0755 /usr/local/bin
        if [ -f /usr/local/bin/fetch-mmds-keys ]; then
            chown root:root /usr/local/bin/fetch-mmds-keys
            chmod 0755 /usr/local/bin/fetch-mmds-keys
        fi
        {{ systemctl restart ssh || true; }}
        {{ systemctl is-active --quiet ssh || true; }}
        # Use explicit true exit to ensure || true works with envctl debug trap
        {{ systemctl start cmux.target 2>/dev/null || true; }}
        """
    )
    await ctx.run("install-systemd-units", cmd)


@registry.task(
    name="install-prompt-wrapper",
    deps=("upload-repo",),
    description="Install prompt-wrapper helper",
)
async def task_install_prompt_wrapper(ctx: TaskContext) -> None:
    repo = shlex.quote(ctx.remote_repo_root)
    cmd = textwrap.dedent(
        f"""
        install -m 0755 {repo}/prompt-wrapper.sh /usr/local/bin/prompt-wrapper
        """
    )
    await ctx.run("install-prompt-wrapper", cmd)


@registry.task(
    name="install-tmux-conf",
    deps=("upload-repo",),
    description="Install tmux configuration",
)
async def task_install_tmux_conf(ctx: TaskContext) -> None:
    repo = shlex.quote(ctx.remote_repo_root)
    cmd = textwrap.dedent(
        f"""
        install -Dm0644 {repo}/configs/tmux.conf /etc/tmux.conf
        """
    )
    await ctx.run("install-tmux-conf", cmd)


@registry.task(
    name="configure-memory-protection",
    deps=("install-systemd-units",),
    description="Configure swapfile and systemd resource protections",
)
async def task_configure_memory_protection(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        set -euo pipefail
        CMUX_FORCE_SWAP=1 CMUX_SWAPFILE_SIZE_GIB=6 /usr/local/sbin/cmux-configure-memory
        expected_kib=$((6 * 1024 * 1024))
        tolerance_kib=8
        min_expected_kib=$((expected_kib - tolerance_kib))
        actual_kib="$(awk '$1 == "/var/swap/cmux-swapfile" {print $3}' /proc/swaps 2>/dev/null || true)"
        if [ -z "${actual_kib}" ]; then
            echo "Swapfile /var/swap/cmux-swapfile missing from /proc/swaps after configuration." >&2
            swapon --show=NAME,TYPE,SIZE,USED,PRIO || true
            exit 1
        fi
        case "${actual_kib}" in
            *[!0-9]*)
                echo "Swapfile size reported as '${actual_kib}' KiB; expected numeric value." >&2
                swapon --show=NAME,TYPE,SIZE,USED,PRIO || true
                exit 1
                ;;
        esac
        if [ "${actual_kib}" -lt "${min_expected_kib}" ]; then
            echo "Swapfile size ${actual_kib} KiB is below required ${min_expected_kib} KiB minimum (6 GiB minus tolerance)." >&2
            swapon --show=NAME,TYPE,SIZE,USED,PRIO || true
            exit 1
        fi
        if [ "${actual_kib}" -lt "${expected_kib}" ]; then
            echo "Swapfile size ${actual_kib} KiB slightly below nominal ${expected_kib} KiB target; continuing (within tolerance ${tolerance_kib} KiB)." >&2
        fi
        """
    )
    await ctx.run("configure-memory-protection", cmd)


@registry.task(
    name="install-collect-scripts",
    deps=("upload-repo",),
    description="Install worker helper scripts",
)
async def task_install_collect_scripts(ctx: TaskContext) -> None:
    repo = shlex.quote(ctx.remote_repo_root)
    cmd = textwrap.dedent(
        f"""
        install -Dm0755 {repo}/apps/worker/scripts/collect-relevant-diff.sh /usr/local/bin/cmux-collect-relevant-diff.sh
        install -Dm0755 {repo}/apps/worker/scripts/collect-crown-diff.sh /usr/local/bin/cmux-collect-crown-diff.sh
        """
    )
    await ctx.run("install-collect-scripts", cmd)


@registry.task(
    name="build-worker",
    deps=("install-repo-dependencies",),
    description="Build worker bundle and install helper scripts",
)
async def task_build_worker(ctx: TaskContext) -> None:
    repo = shlex.quote(ctx.remote_repo_root)
    cmd = textwrap.dedent(
        f"""
        set -euo pipefail
        export PATH="/usr/local/bin:$PATH"
        cd {repo}
        bun build ./apps/worker/src/index.ts \\
          --target node \\
          --outdir ./apps/worker/build \\
          --external @cmux/convex \\
          --external 'node:*'
        if [ ! -f ./apps/worker/build/index.js ]; then
          echo "Worker build output missing at ./apps/worker/build/index.js" >&2
          exit 1
        fi
        install -d /builtins
        cat <<'JSON' > /builtins/package.json
{{"name":"builtins","type":"module","version":"1.0.0"}}
JSON
        rm -rf /builtins/build
        cp -r ./apps/worker/build /builtins/build
        install -Dm0755 ./apps/worker/wait-for-docker.sh /usr/local/bin/wait-for-docker.sh
        """
    )
    await ctx.run("build-worker", cmd)


@registry.task(
    name="build-rust-binaries",
    deps=("upload-repo", "install-rust-toolchain"),
    description="Build Rust binaries with a shared target dir",
)
async def task_build_rust_binaries(ctx: TaskContext) -> None:
    repo = shlex.quote(ctx.remote_repo_root)
    cmd = textwrap.dedent(
        f"""
        set -euo pipefail
        export RUSTUP_HOME=/usr/local/rustup
        export CARGO_HOME=/usr/local/cargo
        export CARGO_TARGET_DIR={repo}/target
        export PATH="${{CARGO_HOME}}/bin:$PATH"
        export CARGO_BUILD_JOBS="$(nproc)"
        cargo build --locked --release --manifest-path {repo}/crates/cmux-env/Cargo.toml
        cargo build --locked --release --manifest-path {repo}/crates/cmux-proxy/Cargo.toml
        cargo build --locked --release --manifest-path {repo}/crates/cmux-pty/Cargo.toml
        """
    )
    await ctx.run("build-rust-binaries", cmd, timeout=60 * 30)


@registry.task(
    name="link-rust-binaries",
    deps=("build-rust-binaries",),
    description="Symlink built Rust binaries into /usr/local/bin",
)
async def task_link_rust_binaries(ctx: TaskContext) -> None:
    repo = shlex.quote(ctx.remote_repo_root)
    cmd = textwrap.dedent(
        f"""
        install -m 0755 {repo}/target/release/envd /usr/local/bin/envd
        install -m 0755 {repo}/target/release/envctl /usr/local/bin/envctl
        install -m 0755 {repo}/target/release/cmux-proxy /usr/local/bin/cmux-proxy
        install -m 0755 {repo}/target/release/cmux-pty /usr/local/bin/cmux-pty
        """
    )
    await ctx.run("link-rust-binaries", cmd)


@registry.task(
    name="configure-envctl",
    deps=("link-rust-binaries", "configure-zsh"),
    description="Configure envctl defaults",
)
async def task_configure_envctl(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        set -eux
        envctl --version
        envctl install-hook bash
        envctl install-hook zsh
        cat <<'PROFILE' > /root/.profile
if [ -n "${ZSH_VERSION:-}" ]; then
  if [ -f ~/.zshrc ]; then
    . ~/.zshrc
  fi
elif [ -n "${BASH_VERSION:-}" ]; then
  if [ -f ~/.bashrc ]; then
    . ~/.bashrc
  fi
elif [ -f ~/.bashrc ]; then
  . ~/.bashrc
fi
PROFILE
        cat <<'PROFILE' > /root/.bash_profile
if [ -n "${ZSH_VERSION:-}" ]; then
  if [ -f ~/.zshrc ]; then
    . ~/.zshrc
  fi
elif [ -n "${BASH_VERSION:-}" ]; then
  if [ -f ~/.bashrc ]; then
    . ~/.bashrc
  fi
elif [ -f ~/.bashrc ]; then
  . ~/.bashrc
fi
PROFILE
        mkdir -p /run/user/0
        chmod 700 /run/user/0
        if ! grep -q 'XDG_RUNTIME_DIR=/run/user/0' /root/.bashrc 2>/dev/null; then
          echo 'export XDG_RUNTIME_DIR=/run/user/0' >> /root/.bashrc
        fi
        if ! grep -q 'cmux-paths.sh' /root/.bashrc 2>/dev/null; then
          echo '[ -f /etc/profile.d/cmux-paths.sh ] && . /etc/profile.d/cmux-paths.sh' >> /root/.bashrc
        fi
        if ! grep -q 'nvm.sh' /root/.bashrc 2>/dev/null; then
          echo '[ -f /etc/profile.d/nvm.sh ] && . /etc/profile.d/nvm.sh' >> /root/.bashrc
        fi
        if ! grep -q 'XDG_RUNTIME_DIR=/run/user/0' /root/.zshrc 2>/dev/null; then
          echo 'export XDG_RUNTIME_DIR=/run/user/0' >> /root/.zshrc
        fi
        """
    )
    await ctx.run("configure-envctl", cmd)


@registry.task(
    name="cleanup-build-artifacts",
    deps=(
        "configure-memory-protection",
        "configure-envctl",
        "configure-openbox",
        "install-prompt-wrapper",
        "install-tmux-conf",
        "install-collect-scripts",
        "setup-claude-oauth-wrappers",
    ),
    description="Remove repository upload and toolchain caches prior to final validation",
)
async def task_cleanup_build_artifacts(ctx: TaskContext) -> None:
    await cleanup_instance_disk(ctx)


@registry.task(
    name="check-cargo",
    deps=("install-rust-toolchain", "cleanup-build-artifacts"),
    description="Verify cargo is installed and working",
)
async def task_check_cargo(ctx: TaskContext) -> None:
    await ctx.run("check-cargo", "PATH=/usr/local/cargo/bin:$PATH cargo --version")


@registry.task(
    name="check-node",
    deps=("install-node-runtime", "cleanup-build-artifacts"),
    description="Verify node is installed and working",
)
async def task_check_node(ctx: TaskContext) -> None:
    await ctx.run("check-node", "node --version")


@registry.task(
    name="check-bun",
    deps=("install-bun", "cleanup-build-artifacts"),
    description="Verify bun is installed and working",
)
async def task_check_bun(ctx: TaskContext) -> None:
    await ctx.run("check-bun", "bun --version && bunx --version")


@registry.task(
    name="check-uv",
    deps=("install-uv-python", "cleanup-build-artifacts"),
    description="Verify uv is installed and working",
)
async def task_check_uv(ctx: TaskContext) -> None:
    await ctx.run("check-uv", "uv --version && uvx --version")


@registry.task(
    name="check-gh",
    deps=("install-base-packages", "cleanup-build-artifacts"),
    description="Verify GitHub CLI is installed and working",
)
async def task_check_gh(ctx: TaskContext) -> None:
    await ctx.run("check-gh", "gh --version")


@registry.task(
    name="check-envctl",
    deps=("configure-envctl", "cleanup-build-artifacts"),
    description="Verify envctl is installed and working",
)
async def task_check_envctl(ctx: TaskContext) -> None:
    await ctx.run("check-envctl", "envctl --version && command -v envd")


@registry.task(
    name="check-ssh-service",
    deps=("configure-memory-protection", "cleanup-build-artifacts"),
    description="Verify SSH service is active",
)
async def task_check_ssh_service(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        set -euo pipefail
        status_output="$(systemctl status ssh --no-pager || true)"
        printf '%s\n' "$status_output"
        if ! systemctl is-active --quiet ssh; then
          echo "ssh service not active; attempting restart..." >&2
          systemctl restart ssh || true
          sleep 2
          status_output="$(systemctl status ssh --no-pager || true)"
          printf '%s\n' "$status_output"
        fi
        if ! systemctl is-active --quiet ssh; then
          echo "ERROR: ssh service status did not report active (running)" >&2
          journalctl -u ssh --no-pager -n 50 || true
          exit 1
        fi
        """
    )
    await ctx.run("check-ssh-service", cmd)


@registry.task(
    name="check-vscode",
    deps=("configure-memory-protection", "cleanup-build-artifacts"),
    description="Verify VS Code endpoint is accessible",
)
async def task_check_vscode(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        for attempt in $(seq 1 15); do
          if curl -fsS -o /dev/null http://127.0.0.1:39378/; then
            echo "IDE endpoint is reachable"
            exit 0
          fi
          sleep 2
        done
        echo "ERROR: IDE endpoint not reachable after 30s" >&2
        systemctl status cmux-ide.service --no-pager || true
        exit 1
        """
    )
    await ctx.run("check-vscode", cmd)


@registry.task(
    name="check-vscode-via-proxy",
    deps=("configure-memory-protection", "cleanup-build-artifacts"),
    description="Verify VS Code endpoint is accessible through cmux-proxy",
)
async def task_check_vscode_via_proxy(ctx: TaskContext) -> None:
    ide_provider = get_ide_provider()
    if ide_provider == IDE_PROVIDER_CODER:
        log_file = "coder.log"
    elif ide_provider == IDE_PROVIDER_CMUX_CODE:
        log_file = "cmux-code.log"
    else:
        log_file = "openvscode.log"
    cmd = textwrap.dedent(
        f"""
        for attempt in $(seq 1 15); do
          if curl -fsS -H 'X-Cmux-Port-Internal: 39378' http://127.0.0.1:39379/ >/dev/null; then
            echo "IDE endpoint is reachable via cmux-proxy"
            exit 0
          fi
          sleep 2
        done
        echo "ERROR: IDE endpoint via cmux-proxy not reachable after 30s" >&2
        systemctl status cmux-proxy.service --no-pager || true
        systemctl status cmux-ide.service --no-pager || true
        tail -n 80 /var/log/cmux/cmux-proxy.log || true
        tail -n 80 /var/log/cmux/{log_file} || true
        exit 1
        """
    )
    await ctx.run("check-vscode-via-proxy", cmd)


@registry.task(
    name="check-pty",
    deps=("install-systemd-units", "cleanup-build-artifacts"),
    description="Verify cmux-pty service is accessible",
)
async def task_check_pty(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        for attempt in $(seq 1 20); do
          if curl -fsS -H 'Accept: application/json' http://127.0.0.1:39383/sessions >/dev/null; then
            echo "cmux-pty endpoint is reachable"
            exit 0
          fi
          sleep 2
        done
        echo "ERROR: cmux-pty endpoint not reachable after 40s" >&2
        systemctl status cmux-pty.service --no-pager || true
        tail -n 80 /var/log/cmux/cmux-pty.log || true
        exit 1
        """
    )
    await ctx.run("check-pty", cmd)


@registry.task(
    name="check-vnc",
    deps=("configure-memory-protection", "cleanup-build-artifacts"),
    description="Verify VNC packages and endpoint are accessible",
)
async def task_check_vnc(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        # Verify VNC binaries are installed
        vncserver -version
        if [ ! -x /usr/local/lib/cmux/cmux-vnc-proxy ]; then
          echo "cmux-vnc-proxy binary missing" >&2
          exit 1
        fi

        # Verify VNC endpoint is accessible
        sleep 5
        for attempt in $(seq 1 15); do
          if curl -fsS -o /dev/null http://127.0.0.1:39380/vnc.html; then
            echo "VNC endpoint is reachable"
            exit 0
          fi
          sleep 2
        done
        echo "ERROR: VNC endpoint not reachable after 30s" >&2
        systemctl status cmux-tigervnc.service --no-pager || true
        systemctl status cmux-vnc-proxy.service --no-pager || true
        systemctl status cmux-devtools.service --no-pager || true
        tail -n 40 /var/log/cmux/chrome.log || true
        tail -n 40 /var/log/cmux/tigervnc.log || true
        tail -n 40 /var/log/cmux/vnc-proxy.log || true
        exit 1
        """
    )
    await ctx.run("check-vnc", cmd)

    websocket_cmd = textwrap.dedent(
        """
        python3 - <<'PY'
import base64
import os
import socket
import sys

host = "127.0.0.1"
port = 39380
path = "/websockify"

key = base64.b64encode(os.urandom(16)).decode()
request = (
    f"GET {path} HTTP/1.1\\r\\n"
    f"Host: {host}:{port}\\r\\n"
    "Upgrade: websocket\\r\\n"
    "Connection: Upgrade\\r\\n"
    f"Sec-WebSocket-Key: {key}\\r\\n"
    "Sec-WebSocket-Version: 13\\r\\n"
    "\\r\\n"
)

with socket.create_connection((host, port), timeout=5) as sock:
    sock.settimeout(5)
    sock.sendall(request.encode("ascii"))
    resp = sock.recv(1024).decode("latin1", "replace")

status_line = resp.splitlines()[0] if resp else ""
if not status_line.startswith("HTTP/1.1 101"):
    print(f"Unexpected websocket response: {status_line!r}", file=sys.stderr)
    sys.exit(1)
PY
        """
    )
    await ctx.run("check-vnc-websocket-upgrade", websocket_cmd)


@registry.task(
    name="check-devtools",
    deps=("configure-memory-protection", "cleanup-build-artifacts"),
    description="Verify Chrome browser and DevTools endpoint are accessible",
)
async def task_check_devtools(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        # Verify Chrome is installed
        google-chrome --version

        # Verify DevTools endpoint is accessible
        sleep 5
        for attempt in $(seq 1 45); do
          if curl -fsS -o /dev/null http://127.0.0.1:39381/json/version; then
            echo "DevTools endpoint is reachable"
            exit 0
          fi
          sleep 2
        done
        echo "ERROR: DevTools endpoint not reachable after 90s" >&2
        systemctl status cmux-devtools.service --no-pager || true
        systemctl status cmux-cdp-proxy.service --no-pager || true
        ss -ltnp | grep 3938 || true
        tail -n 100 /var/log/cmux/chrome.log || true
        tail -n 40 /var/log/cmux/tigervnc.log || true
        exit 1
        """
    )
    await ctx.run("check-devtools", cmd)


@registry.task(
    name="check-worker",
    deps=("configure-memory-protection", "cleanup-build-artifacts"),
    description="Verify worker service is running",
)
async def task_check_worker(ctx: TaskContext) -> None:
    cmd = textwrap.dedent(
        """
        set -euo pipefail
        for attempt in $(seq 1 30); do
          if systemctl is-active --quiet cmux-worker.service; then
            if health="$(curl -fsS http://127.0.0.1:39377/health)"; then
              printf '%s\n' "$health"
              exit 0
            fi
          fi
          sleep 2
        done
        echo "ERROR: cmux-worker service failed health check" >&2
        systemctl status cmux-worker.service --no-pager || true
        tail -n 80 /var/log/cmux/worker.log || true
        exit 1
        """
    )
    await ctx.run("check-worker", cmd)


# ---------------------------------------------------------------------------
# Cleanup and verification helpers
# ---------------------------------------------------------------------------


async def verify_devtools_via_exposed_url(
    port_map: dict[int, str],
    *,
    console: Console,
) -> None:
    cdp_base_url = port_map.get(CDP_HTTP_PORT)
    if cdp_base_url is None:
        raise RuntimeError("Failed to expose DevTools service URL via Morph")
    version_url = urllib.parse.urljoin(
        cdp_base_url.rstrip("/") + "/",
        "json/version",
    )
    console.info(f"Verifying DevTools via exposed URL: {version_url}")
    max_attempts = 45
    async with httpx.AsyncClient(
        timeout=httpx.Timeout(5.0, connect=5.0, read=5.0),
        follow_redirects=True,
    ) as client:
        for attempt in range(1, max_attempts + 1):
            try:
                response = await client.get(
                    version_url,
                    headers={"Accept": "application/json"},
                )
            except (httpx.HTTPError, ssl.SSLError, OSError) as exc:
                console.info(
                    f"Attempt {attempt}/{max_attempts} failed to reach DevTools via Morph: {exc}"
                )
            else:
                if response.status_code == httpx.codes.OK:
                    console.info("DevTools endpoint is reachable via Morph exposed URL")
                    return
                console.info(
                    f"Attempt {attempt}/{max_attempts} returned HTTP "
                    f"{response.status_code} from DevTools via Morph"
                )
            if attempt < max_attempts:
                await asyncio.sleep(2)
    raise RuntimeError(
        "DevTools endpoint not reachable via Morph exposed URL after multiple attempts"
    )


async def snapshot_instance(
    instance: Instance,
    *,
    console: Console,
) -> Snapshot:
    console.info(f"Snapshotting instance {instance.id}...")
    snapshot = await instance.asnapshot()
    console.info(f"Created snapshot {snapshot.id}")
    return snapshot


async def cleanup_instance_disk(ctx: TaskContext) -> None:
    ctx.console.info("Cleaning up build artifacts before snapshot...")
    repo = shlex.quote(ctx.remote_repo_root)
    tar_path = shlex.quote(ctx.remote_repo_tar)
    cleanup_script = textwrap.dedent(
        f"""
        set -euo pipefail
        rm -rf {repo}
        rm -f {tar_path}
        if [ -d /usr/local/cargo ]; then
            rm -rf /usr/local/cargo/registry
            rm -rf /usr/local/cargo/git
            install -d -m 0755 /usr/local/cargo/registry
            install -d -m 0755 /usr/local/cargo/git
        fi
        if [ -d /usr/local/rustup ]; then
            rm -rf /usr/local/rustup/tmp
            rm -rf /usr/local/rustup/downloads
            install -d -m 0755 /usr/local/rustup/tmp
            install -d -m 0755 /usr/local/rustup/downloads
        fi
        if [ -d /root/.cache ]; then
            rm -rf /root/.cache/go-build
            rm -rf /root/.cache/pip
            rm -rf /root/.cache/uv
            rm -rf /root/.cache/bun
        fi
        if [ -d /root/.bun ]; then
            rm -rf /root/.bun/install/cache
        fi
        rm -rf /root/.npm
        rm -rf /root/.pnpm-store
        rm -rf /root/go
        rm -rf /usr/local/go-workspace/bin
        rm -rf /usr/local/go-workspace/pkg/mod
        rm -rf /usr/local/go-workspace/pkg/sumdb
        rm -rf /usr/local/go-cache
        install -d -m 0755 /root/.cache
        install -d -m 0755 /root/.cache/go-build
        install -d -m 0755 /root/.cache/pip
        install -d -m 0755 /root/.cache/uv
        install -d -m 0755 /root/.cache/bun
        install -d -m 0755 /usr/local/go-workspace
        install -d -m 0755 /usr/local/go-workspace/bin
        install -d -m 0755 /usr/local/go-workspace/pkg/mod
        install -d -m 0755 /usr/local/go-workspace/pkg/sumdb
        install -d -m 0755 /usr/local/go-cache
        if [ -d /var/cache/apt ]; then
            rm -rf /var/cache/apt/archives/*.deb
            rm -rf /var/cache/apt/archives/partial
            install -d -m 0755 /var/cache/apt/archives/partial
        fi
        if [ -d /var/lib/apt/lists ]; then
            find /var/lib/apt/lists -mindepth 1 -maxdepth 1 -type f -delete
            rm -rf /var/lib/apt/lists/partial
            install -d -m 0755 /var/lib/apt/lists/partial
        fi
        """
    ).strip()
    await ctx.run("cleanup-disk-artifacts", cleanup_script)


async def report_disk_usage(ctx: TaskContext) -> None:
    ctx.console.info("Collecting disk usage statistics...")
    disk_script = textwrap.dedent(
        """
        set -euo pipefail
        echo "==== Disk usage (df -h /) ===="
        df -h /
        echo
        echo "==== Key directories ===="
        for path in /var/swap /cmux /usr/local /usr/local/go-workspace /usr/local/cargo /root; do
            if [ -e "$path" ]; then
                du -sh "$path" 2>/dev/null || true
            fi
        done
        echo
        """
    ).strip()
    await ctx.run("disk-usage-summary", disk_script)


# ---------------------------------------------------------------------------
# Main provisioning flow
# ---------------------------------------------------------------------------


async def provision_and_snapshot_for_preset(
    args: argparse.Namespace,
    *,
    preset: SnapshotPresetPlan,
    console: Console,
    client: MorphCloudClient,
    repo_root: Path,
    started_instances: list[Instance],
    require_verify: bool,
    show_dependency_graph: bool,
) -> SnapshotRunResult:
    console.always(
        f"\n=== Provisioning preset {preset.preset_id} ({preset.label}) ==="
    )
    timings = TimingsCollector()

    instance = await client.instances.aboot(
        args.snapshot_id,
        vcpus=preset.vcpus,
        memory=preset.memory_mib,
        disk_size=preset.disk_size_mib,
        ttl_seconds=args.ttl_seconds,
        ttl_action=args.ttl_action,
    )
    await instance.aset_wake_on(wake_on_http=True)
    started_instances.append(instance)
    await _await_instance_ready(instance, console=console)
    console.always(
        f"[{preset.preset_id}] Dashboard: https://cloud.morph.so/web/instances/{instance.id}?ssh=true"
    )
    port_map = await _expose_standard_ports(instance, console)
    exec_service_url = port_map.get(EXEC_HTTP_PORT)
    if exec_service_url is None:
        raise RuntimeError("Failed to expose exec service port on primary instance")

    resource_profile = _build_resource_profile(preset.vcpus, preset.memory_mib)

    ctx = TaskContext(
        instance=instance,
        repo_root=repo_root,
        remote_repo_root="/cmux",
        remote_repo_tar="/tmp/cmux-repo.tar",
        console=console,
        timings=timings,
        resource_profile=resource_profile,
        exec_service_url=exec_service_url,
    )

    await run_task_graph(registry, ctx)
    await verify_devtools_via_exposed_url(port_map, console=console)

    if show_dependency_graph:
        graph = format_dependency_graph(registry)
        if graph:
            console.always("\nDependency Graph")
            for line in graph.splitlines():
                console.always(line)

    summary = timings.summary()
    if summary:
        console.always("\nTiming Summary")
        for line in summary:
            console.always(line)

    await report_disk_usage(ctx)

    vscode_url = port_map.get(VSCODE_HTTP_PORT)
    if vscode_url is None:
        raise RuntimeError("Failed to expose VS Code service URL")
    vnc_base_url = port_map.get(VNC_HTTP_PORT)
    if vnc_base_url is None:
        raise RuntimeError("Failed to expose VNC service URL")
    vnc_url = urllib.parse.urljoin(vnc_base_url.rstrip("/") + "/", "vnc.html")

    console.always(f"[{preset.preset_id}] VS Code: {vscode_url}")
    console.always(f"[{preset.preset_id}] VNC: {vnc_url}")

    send_macos_notification(
        console,
        f"Verify cmux workspace â€“ {preset.label}",
        f"VS Code: {vscode_url} / VNC: {vnc_url}",
    )
    console.info("Sent verification notification (macOS only).")

    if require_verify:
        await _prompt_verification_for_preset(
            preset.preset_id, vscode_url, vnc_url, console
        )

    await cleanup_instance_disk(ctx)
    snapshot = await snapshot_instance(instance, console=console)
    captured_at = _iso_timestamp()

    console.always(f"[{preset.preset_id}] Snapshot created: {snapshot.id}")
    console.always(
        f"[{preset.preset_id}] Provisioning complete. Snapshot id: {snapshot.id}"
    )
    console.always(f"[{preset.preset_id}] Instance: {instance.id}")

    return SnapshotRunResult(
        preset=preset,
        snapshot=snapshot,
        captured_at=captured_at,
        vscode_url=vscode_url,
        vnc_url=vnc_url,
        instance_id=instance.id,
    )


async def provision_and_snapshot(args: argparse.Namespace) -> None:
    # Set the IDE provider before running tasks
    set_ide_provider(args.ide_provider)

    console = Console()
    client = MorphCloudClient()
    started_instances: list[Instance] = []
    manifest = _load_manifest(console)
    results: list[SnapshotRunResult] = []

    def _cleanup() -> None:
        if args.require_verify:
            while started_instances:
                inst = started_instances.pop()
                _stop_instance(inst, console)

    def _sync_cleanup() -> None:
        _cleanup()

    atexit.register(_sync_cleanup)

    repo_root = Path(args.repo_root).resolve()
    if getattr(args, "bump_ide_deps", False):
        bun_path = shutil.which("bun")
        if bun_path is None:
            raise RuntimeError(
                "bun not found on host; install bun or rerun with --no-bump-ide-deps."
            )
        console.always("Bumping IDE deps to latest (bun run bump-ide-deps)...")
        bump_result = subprocess.run(
            [bun_path, "run", "bump-ide-deps"],
            cwd=str(repo_root),
            text=True,
        )
        if bump_result.returncode != 0:
            raise RuntimeError(
                f"bun run bump-ide-deps failed with exit code {bump_result.returncode}"
            )
    preset_plans = _build_preset_plans(args)

    console.always(
        "Starting snapshot runs for presets "
        f"{', '.join(plan.preset_id for plan in preset_plans)} "
        f"from base snapshot {args.snapshot_id} "
        f"(IDE provider: {args.ide_provider})"
    )

    preset_order: dict[str, int] = {
        plan.preset_id: index for index, plan in enumerate(preset_plans)
    }
    tasks = [
        asyncio.create_task(
            provision_and_snapshot_for_preset(
                args,
                preset=preset_plan,
                console=console,
                client=client,
                repo_root=repo_root,
                started_instances=started_instances,
                require_verify=args.require_verify,
                show_dependency_graph=index == 0,
            )
        )
        for index, preset_plan in enumerate(preset_plans)
    ]

    results = await asyncio.gather(*tasks)
    ordered_results = sorted(
        results,
        key=lambda item: preset_order.get(item.preset.preset_id, 0),
    )

    if not args.require_verify:
        for result in ordered_results:
            try:
                inst = client.instances.get(instance_id=result.instance_id)
                inst.set_ttl(ttl_seconds=600, ttl_action="pause")
                console.always(
                    f"[{result.preset.preset_id}] Instance {result.instance_id} "
                    "will pause in ~10 minutes (TTL set)."
                )
            except Exception as exc:
                console.always(
                    f"[{result.preset.preset_id}] Failed to set TTL on instance "
                    f"{result.instance_id}: {exc}"
                )

    for result in ordered_results:
        manifest = _update_manifest_with_snapshot(
            manifest, result.preset, result.snapshot.id, result.captured_at
        )
    _write_manifest(manifest)

    _render_verification_table(ordered_results, console)

    console.always(
        f"\nUpdated morph snapshot manifest at {MORPH_SNAPSHOT_MANIFEST_PATH}"
    )
    for result in ordered_results:
        console.always(
            f"[{result.preset.preset_id}] Snapshot {result.snapshot.id} captured at {result.captured_at}"
        )


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Provision Morph instance with parallel setup"
    )
    parser.add_argument(
        "--snapshot-id",
        default="snapshot_3fjuvxbs",
        help="Base snapshot id to boot from",
    )
    parser.add_argument(
        "--repo-root",
        default=".",
        help="Repository root to upload (default: current directory)",
    )
    parser.add_argument(
        "--standard-vcpus",
        "--vcpus",
        dest="standard_vcpus",
        type=int,
        default=4,
        help="vCPU count for the standard preset",
    )
    parser.add_argument(
        "--standard-memory",
        "--memory",
        dest="standard_memory",
        type=int,
        default=16_384,
        help="Memory (MiB) for the standard preset",
    )
    parser.add_argument(
        "--standard-disk-size",
        "--disk-size",
        dest="standard_disk_size",
        type=int,
        # 48gb
        default=49_152,
        help="Disk size (MiB) for the standard preset",
    )
    parser.add_argument(
        "--boosted-vcpus",
        type=int,
        default=8,
        help="vCPU count for the boosted preset",
    )
    parser.add_argument(
        "--boosted-memory",
        type=int,
        default=32_768,
        help="Memory (MiB) for the boosted preset",
    )
    parser.add_argument(
        "--boosted-disk-size",
        type=int,
        default=49_152,
        help="Disk size (MiB) for the boosted preset",
    )
    parser.add_argument(
        "--ttl-seconds",
        type=int,
        default=3600,
        help="TTL seconds for created instances",
    )
    parser.add_argument(
        "--ttl-action",
        default="pause",
        choices=("pause", "stop"),
        help="Action when TTL expires",
    )
    parser.add_argument(
        "--print-deps",
        action="store_true",
        help="Print dependency graph and exit",
    )
    parser.add_argument(
        "--require-verify",
        action="store_true",
        help="Require manual verification (VS Code/VNC) before snapshotting each preset",
    )
    parser.add_argument(
        "--ide-provider",
        choices=(IDE_PROVIDER_CODER, IDE_PROVIDER_OPENVSCODE, IDE_PROVIDER_CMUX_CODE),
        default=DEFAULT_IDE_PROVIDER,
        help=f"IDE provider to install (default: {DEFAULT_IDE_PROVIDER})",
    )
    parser.add_argument(
        "--bump-ide-deps",
        dest="bump_ide_deps",
        action=argparse.BooleanOptionalAction,
        default=True,
        help="Update configs/ide-deps.json to latest versions before snapshotting",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    if getattr(args, "print_deps", False):
        graph = format_dependency_graph(registry)
        if graph:
            print(graph)
        return
    try:
        asyncio.run(provision_and_snapshot(args))
    except Exception as exc:
        traceback.print_exc()
        send_scary_notification(f"Snapshot run failed: {exc}")
        raise


if __name__ == "__main__":
    main()
